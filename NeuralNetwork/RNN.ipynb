{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15Wn_qoWKvkC3-B_5QIATW_Fvkb2keAfK","authorship_tag":"ABX9TyOnnYqcl4gutT1C0vlYK4Uf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"Uc3-8DzNn0ei","executionInfo":{"status":"ok","timestamp":1736260764464,"user_tz":-210,"elapsed":412,"user":{"displayName":"cactus almasi","userId":"10340650331342810186"}}},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","source":["class MyRnn(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.e = nn.Embedding(5000, 256)\n","    self.rnn = nn.GRU(256, 512, 4)   # We can use RNN or GRU or LSTM\n","    self.linear = nn.Linear(512, 2)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    # x = l x B\n","    x_e = self.e(x)\n","    # x_e = l x B x 256\n","    _, h =self.rnn(x_e)\n","    last_h = h[-1]\n","\n","    y = self.linear(last_h)\n","    y_s = self.sigmoid(y)\n","\n","    return y_s\n","\n","\n","net = MyRnn()\n","\n","x = torch.tensor([[0, 1, 2, 500, 45], [455, 89, 94, 322, 1000]]).T\n","\n","y = net(x)\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INgKWaRxwIfy","executionInfo":{"status":"ok","timestamp":1736260766422,"user_tz":-210,"elapsed":2,"user":{"displayName":"cactus almasi","userId":"10340650331342810186"}},"outputId":"a4493125-8085-4e5e-c95e-e83cedafaffa"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class IMDBDataSet(Dataset):\n","    def __init__(self, file_path: str, tokenizer_name: str = \"bert-base-uncased\"):\n","        self.sentences = []\n","        self.labels = []\n","        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n","\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            lines = f.readlines()\n","            for line in lines[1:]:  # Skip header\n","                split_line = line.strip().split(',')\n","                text = split_line[0]\n","                label = split_line[1]\n","                self.sentences.append(text)\n","                self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def convert_label(self, label: str) -> torch.tensor:\n","        return torch.tensor([1, 0] if label == \"positive\" else [0, 1], dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.tokenizer(\n","            self.sentences[idx],\n","            padding='max_length',\n","            truncation=True,\n","            max_length=128,\n","            return_tensors=\"pt\"\n","        )[\"input_ids\"].squeeze(0)\n","\n","        input_ids[input_ids >= 5000] = 0\n","\n","        target = self.convert_label(self.labels[idx])\n","        return input_ids, target\n","\n","\n","\n","def pad_collate(batch):\n","    input_batch = [item[0] for item in batch]\n","    target_batch = [item[1] for item in batch]\n","\n","    input_batch = torch.nn.utils.rnn.pad_sequence(input_batch, batch_first=True, padding_value=0)\n","    target_batch = torch.stack(target_batch)\n","\n","    return input_batch, target_batch\n","\n","\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/IMDB-Dataset.csv\"\n","imdb_data = IMDBDataSet(file_path)\n","loader = DataLoader(imdb_data, batch_size=128, shuffle=True, collate_fn=pad_collate)\n","\n","for input_batch, target_batch in loader:\n","    print(\"Input Batch Shape:\", input_batch.shape)\n","    print(\"Target Batch Shape:\", target_batch.shape)\n","    break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKfEvBrxz1jI","executionInfo":{"status":"ok","timestamp":1736271032917,"user_tz":-210,"elapsed":771,"user":{"displayName":"cactus almasi","userId":"10340650331342810186"}},"outputId":"96455516-9912-4f58-f58d-9fae4b157c2e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Batch Shape: torch.Size([128, 128])\n","Target Batch Shape: torch.Size([128, 2])\n"]}]},{"cell_type":"code","source":["from torch.optim import Adam\n","\n","net = MyRnn()\n","opt = Adam(net.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()\n","\n","\n","for epoch in range(1000):\n","  sum_loss = 0\n","  for i, batch in enumerate(loader):\n","\n","    inputs = batch[0]\n","    targets = batch[1]\n","\n","    y = net(inputs)\n","\n","    loss_value = loss_func(y, targets)\n","\n","    loss_value.backward()\n","\n","    opt.step()\n","\n","    sum_loss += loss_value.item()\n","    print(f'Loss: {sum_loss / (i + 1)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"collapsed":true,"id":"ly-PYJhV9mq2","executionInfo":{"status":"error","timestamp":1736271208028,"user_tz":-210,"elapsed":46119,"user":{"displayName":"cactus almasi","userId":"10340650331342810186"}},"outputId":"385639fd-4fcd-4b9e-bc04-dc14e034dfc3"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.6953949332237244\n","Loss: 0.5772836953401566\n","Loss: 0.4978826542695363\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-2f852a8a6863>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}